{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image\n",
    "\n",
    "from sam2.build_sam import build_sam2_object_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self,\n",
    "                 video_width,\n",
    "                 video_height,\n",
    "                 ):\n",
    "        \n",
    "        self.video_width = video_width\n",
    "        self.video_height = video_height\n",
    "\n",
    "    def resize_mask(self, mask):\n",
    "        mask = torch.tensor(mask, device='cpu')\n",
    "        mask = torch.nn.functional.interpolate(mask,\n",
    "                                               size=(self.video_height, self.video_width),\n",
    "                                               mode=\"bilinear\",\n",
    "                                               align_corners=False,\n",
    "                                               )\n",
    "        \n",
    "        return mask\n",
    "\n",
    "    def add_frame(self, frame, mask):\n",
    "        frame = frame.copy()\n",
    "        frame = cv2.resize(frame, (self.video_width, self.video_height))\n",
    "        \n",
    "        mask = self.resize_mask(mask=mask)\n",
    "        mask = (mask > 0.0).numpy()\n",
    "        \n",
    "        for i in range(mask.shape[0]):\n",
    "            obj_mask = mask[i, 0, :, :]\n",
    "            frame[obj_mask] = [255, 105, 180]\n",
    "                \n",
    "        rgb_frame = Image.fromarray(frame)\n",
    "        clear_output(wait=True)\n",
    "        display(rgb_frame)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68bf93105a7b2da1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download Example Video\n",
    "VIDEO_STREAM = \"./TUD-Stadtmitte-raw.webm\"\n",
    "url = 'https://motchallenge.net/sequenceVideos/TUD-Stadtmitte-raw.webm'\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(VIDEO_STREAM):\n",
    "    # If the file doesn't exist, download it\n",
    "    urllib.request.urlretrieve(url, VIDEO_STREAM)\n",
    "    print(f\"Downloading {VIDEO_STREAM}...\")\n",
    "else:\n",
    "    print(f\"File {VIDEO_STREAM} already exists, skipping download.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb1780f6714552fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set SAM2 Configuration\n",
    "NUM_OBJECTS = 2\n",
    "YOLO_CHECKPOINT_FILEPATH = \"yolov8x-seg.pt\"\n",
    "SAM_CHECKPOINT_FILEPATH = \"../checkpoints/sam2.1_hiera_base_plus.pt\"\n",
    "SAM_CONFIG_FILEPATH = \"./configs/samurai/sam2.1_hiera_b+.yaml\"\n",
    "OUTPUT_PATH = VIDEO_STREAM + \"_segmented.mp4\"\n",
    "DEVICE = 'cuda:0'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26eb66ca244d0f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Open Video Stream\n",
    "video_stream = cv2.VideoCapture(VIDEO_STREAM)\n",
    "\n",
    "video_height = int(video_stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "video_width = int(video_stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# For real-time visualization\n",
    "visualizer = Visualizer(video_width=video_width,\n",
    "                        video_height=video_height\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d909a1eff131e1e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = build_sam2_object_tracker(num_objects=NUM_OBJECTS,\n",
    "                                config_file=SAM_CONFIG_FILEPATH,\n",
    "                                ckpt_path=SAM_CHECKPOINT_FILEPATH,\n",
    "                                device=DEVICE,\n",
    "                                verbose=False\n",
    "                                )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4394d77e3b63645"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "available_slots = np.inf\n",
    "\n",
    "first_frame = True\n",
    "with torch.inference_mode(), torch.autocast('cuda:0', dtype=torch.bfloat16):\n",
    "    while video_stream.isOpened():\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Get next frame\n",
    "        ret, frame = video_stream.read()\n",
    "        \n",
    "        # Exit if no frames remaining\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame from BGR to RGB\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Simulate detection on first frame\n",
    "        if first_frame:\n",
    "            \n",
    "            cv2.imwrite('output_image.jpg', img)\n",
    "            bbox = np.array([[[172, 92], [254, 325]], \n",
    "                             [[334, 76],  [439, 329]]]\n",
    "                            )\n",
    "            \n",
    "            sam_out = sam.track_new_object(img=img,\n",
    "                                           box=bbox\n",
    "                                           )\n",
    "            \n",
    "            first_frame = False\n",
    "            \n",
    "        else:\n",
    "            sam_out = sam.track_all_objects(img=img)\n",
    "            \n",
    "        visualizer.add_frame(frame=frame, mask=sam_out['pred_masks'])\n",
    "        \n",
    "video_stream.release()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df2d1a1e04cfa1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f82a4fd8bafcf9b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
